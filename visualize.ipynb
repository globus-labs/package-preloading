{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:11.238891Z",
     "start_time": "2024-04-06T03:08:11.233047Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b0a5ff0543ef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:13.443629Z",
     "start_time": "2024-04-06T03:08:13.441938Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def prepare(data):\n",
    "    data['import.start'] = pd.to_datetime(data['import.start'])\n",
    "    data['import.stop'] = pd.to_datetime(data['import.stop'])\n",
    "    data['created'] = pd.to_datetime(data['created'])\n",
    "    data['started'] = pd.to_datetime(data['started'])\n",
    "    data['finished'] = pd.to_datetime(data['finished'])\n",
    "    \n",
    "    data['starttime'] = (data['started'] - data['creavisualize.ipynbted']).dt.total_seconds() \n",
    "    data['dockertime'] = (data['finished'] - data['started']).dt.total_seconds() \n",
    "    data['importtime'] = (data['import.stop'] - data['import.start']).dt.total_seconds() \n",
    "    \n",
    "    started_temp = pd.DataFrame()\n",
    "    docker_temp = pd.DataFrame()\n",
    "    import_temp = pd.DataFrame()\n",
    "    \n",
    "    for i in range(8,29,5):\n",
    "        started_temp.insert(range(8,29,5).index(i), \"\", (pd.to_datetime(data.iloc[:, i+1]) - pd.to_datetime(data.iloc[:, i])).dt.total_seconds() , True)\n",
    "        docker_temp.insert(range(8,29,5).index(i), \"\", (pd.to_datetime(data.iloc[:, i+2]) - pd.to_datetime(data.iloc[:, i+1])).dt.total_seconds() , True)\n",
    "        import_temp.insert(range(8,29,5).index(i), \"\", (pd.to_datetime(data.iloc[:, i+4]) - pd.to_datetime(data.iloc[:, i+3])).dt.total_seconds() , True)\n",
    "        \n",
    "    \n",
    "    started_temp.columns = ['starttime{}'.format(i) for i in range(1, 6)]\n",
    "    docker_temp.columns = ['dvisualize.ipynbockertime{}'.format(i) for i in range(1, 6)]\n",
    "    import_temp.columns = ['importtime{}'.format(i) for i in range(1, 6)]\n",
    "    \n",
    "    data = pd.concat([data, started_temp, docker_temp, import_temp], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa1b98486e816909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:15.229894Z",
     "start_time": "2024-04-06T03:08:15.228570Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def extract_imports(imp):\n",
    "    imp = imp.split(\"'\")\n",
    "    l = \"\"\n",
    "    \n",
    "    for i in imp:\n",
    "        if i == \"(\" or i == \")\" or i == \",)\" or i == \",\" or i == \"()\" or i == \", \":\n",
    "            continue\n",
    "        else:\n",
    "            if l == \"\":\n",
    "                l = i\n",
    "            else:\n",
    "                l = l + \";\" + i\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2b16992b94fa98",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This is one experiment run with using the top 10 packages over all functions\n",
    "The installationtime is set to minus -1 if there was no install as for native python packages as os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ea9358d1388ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:47:37.621736Z",
     "start_time": "2024-04-09T19:47:37.617673Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "approach = \"all_top_10\"\n",
    "col = ['imports', 'buldingtime', 'installtime', 'starttime', 'dockertime',\n",
    "       'importtime', 'starttime1', 'starttime2', 'starttime3', 'starttime4',\n",
    "       'starttime5', 'dockertime1', 'dockertime2', 'dockertime3',\n",
    "       'dockertime4', 'dockertime5', 'importtime1', 'importtime2',\n",
    "       'importtime3', 'importtime4', 'importtime5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a4bf12f4164f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:47:40.722354Z",
     "start_time": "2024-04-09T19:47:40.698292Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'creavisualize.ipynbted'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'creavisualize.ipynbted'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mapproach\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/run10.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m imp \u001b[38;5;241m=\u001b[39m data[col[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m data[col[\u001b[38;5;241m1\u001b[39m:]]\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarttime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreavisualize.ipynbted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtotal_seconds() \n\u001b[1;32m      9\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdockertime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtotal_seconds() \n\u001b[1;32m     10\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimporttime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimport.stop\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimport.start\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtotal_seconds() \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'creavisualize.ipynbted'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/\"+approach+\"/run10.csv\")\n",
    "data = prepare(data)\n",
    "imp = data[col[0]]\n",
    "data = data[col[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd342f5564b028b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:47:43.141334Z",
     "start_time": "2024-04-09T19:47:42.972822Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(9,0,-1):\n",
    "    tmp = pd.read_csv(\"data/\"+approach+\"/run0\"+str(i)+\".csv\")\n",
    "    tmp = prepare(tmp)\n",
    "    tmp = tmp[col[1:]]\n",
    "    data = (data + tmp)\n",
    "data = data/10\n",
    "data.insert(0, col[0],imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05fb5f6459b67b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:47:47.639015Z",
     "start_time": "2024-04-09T19:47:47.634607Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ceed409045138",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This is the mapping between imports and function\n",
    "For this merge and the following ones, there is no need to think about on which join-operation. I cleaned the data beforehand. That is, there will be always a pair \n",
    "```python\n",
    "pd.merge(func_mapping,data, on='imports')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f29b04d35b7e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:24.027052Z",
     "start_time": "2024-04-06T03:08:24.002654Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "func_mapping = pd.read_csv('experiments/function_mapping.csv')\n",
    "func_mapping = func_mapping.drop(2)\n",
    "func_mapping['func4.imports'] = func_mapping[func_mapping['func4.imports'].str.len() >= 0]['func4.imports'].map(lambda x: extract_imports(x))\n",
    "func_mapping = func_mapping[func_mapping['func4.imports'] != \"\"]\n",
    "func_mapping.rename(columns={'func4.imports': 'imports'}, inplace=True)\n",
    "func_mapping.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0774177c6d33e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:25.830936Z",
     "start_time": "2024-04-06T03:08:25.825219Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "func_mapping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea7d1de6fcc4133",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Here is the mapping between functions and task\n",
    "```python\n",
    "pd.merge(func_mapping,task_mapping, on='func4.name')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9db0d236f73cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:28.436627Z",
     "start_time": "2024-04-06T03:08:27.622684Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task_mapping = pd.read_csv(\"funcx/task_function_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43b239175454a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:28.441554Z",
     "start_time": "2024-04-06T03:08:28.438275Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task_mapping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356aaf6a14c523f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Here we have the timestamp for each task\n",
    "For merging\n",
    "```python\n",
    "pd.merge(task_mapping,task_mapping, on='task_uuid')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3bd22dded8555f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:31.327015Z",
     "start_time": "2024-04-06T03:08:30.406782Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = pd.read_csv(\"funcx/tasks_pt1.csv\")\n",
    "task = pd.concat([task, pd.read_csv(\"funcx/tasks_pt2.csv\")], ignore_index=True)\n",
    "task['received'] = task['received'].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f3b2d5c05fe98e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:33.258452Z",
     "start_time": "2024-04-06T03:08:33.252693Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43beb653edaa8e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Here are information about the endpoints\n",
    "For merging:\n",
    "```python\n",
    "pd.merge(task,endpoints, on='endpoint_uuid')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498689f1fefc6a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:35.309136Z",
     "start_time": "2024-04-06T03:08:35.306266Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "endpoints = pd.read_csv(\"funcx/endpoints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d59ea84205f9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T03:08:37.026566Z",
     "start_time": "2024-04-06T03:08:37.016453Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "endpoints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed31d7a5e47d9b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Example merging in the end:\n",
    "```python\n",
    "o = pd.merge(func_mapping,data, on='imports')\n",
    "p = pd.merge(task_mapping,o, on='func4.name')\n",
    "r = pd.merge(task, p, on='task_uuid')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f104c45432cb9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "o = pd.merge(func_mapping,data, on='imports')\n",
    "p = pd.merge(task_mapping,o, on='func4.name')\n",
    "r = pd.merge(task, p, on='task_uuid')\n",
    "r.to_csv(\"my_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66359c-da51-4767-a768-91bac56f54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = r.sort_values(by=[\"received\"], ascending=True)\n",
    "sorted_df.to_csv(\"my_data_sorted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f814346-1678-4c83-93ca-a2ac78a0e757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
